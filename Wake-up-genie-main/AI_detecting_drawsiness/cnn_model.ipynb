{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ada7da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985563c6",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d8ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data와 validation data 로드\n",
    "x_train = np.load('../data/x_train.npy').astype(np.float32)\n",
    "y_train = np.load('../data/y_train.npy').astype(np.float32)\n",
    "x_val = np.load('../data/x_val.npy').astype(np.float32)\n",
    "y_val = np.load('../data/y_val.npy').astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30feeb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2647, 26, 34, 1) (2647, 1)\n",
      "(295, 26, 34, 1) (295, 1)\n"
     ]
    }
   ],
   "source": [
    "# label : 눈을 감고 있는 이미지 = 1 / 눈을 뜨고 있는 이미지 = 0\n",
    "print(x_train.shape, y_train.shape) #2647장 * 26 * 34 * 1 / 2647 * 1\n",
    "print(x_val.shape, y_val.shape) #295장 * 26 * 34  * 1 / 295 * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e86b792",
   "metadata": {},
   "source": [
    "# Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857d1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증식을 위해 사용할 ImageDataGenerator 객체 생성\n",
    "# training data\n",
    "# 정확도를 높이기 위해 랜덤하게 이미지를 리스케일링\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,             # 크기 재조절 (픽셀값을 0~1사이 값으로 변경)\n",
    "    rotation_range=10,          # 무작위 회전\n",
    "    width_shift_range=0.2,      # 이미지 수평 방향 이동\n",
    "    height_shift_range=0.2,     # 이미지 수직 방향 이동\n",
    "    shear_range=0.2             # 밀림 강도\n",
    ")\n",
    "\n",
    "\n",
    "# validation data\n",
    "# 따로 데이터 스케일과정이 필요없으므로 픽셀값만 0~1사이의 값으로 변경\n",
    "val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# 이미지 변형(batch size, shuffle 여부 정의)\n",
    "# training data\n",
    "train_generator = train_datagen.flow(\n",
    "    x=x_train, y=y_train,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#validation data\n",
    "val_generator = val_datagen.flow(\n",
    "    x=x_val, y=y_val,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82618202",
   "metadata": {},
   "source": [
    "# Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b130d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26, 34, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 34, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 17, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 361,345\n",
      "Trainable params: 361,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# layer는 convolution layer 4개, pooling layer 4개 이후 fully connected layer로 구성\n",
    "# 0~1사이의 값으로 구성된 26*34*1의 픽셀 값들을 입력으로 받아 이미지가 opened eye(1) 인지 closed eye(0)인지 분류\n",
    "inputs = keras.layers.Input(shape=(26, 34, 1))\n",
    "\n",
    "net = keras.layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "net = keras.layers.MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = keras.layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = keras.layers.MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = keras.layers.MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = keras.layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu')(net)\n",
    "net = keras.layers.MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = keras.layers.Flatten()(net)                           # convolution layer와 pooling layer를 통과하며 특징을 1차원으로 변환\n",
    "\n",
    "net = keras.layers.Dense(1024)(net)                         # fully connected layer\n",
    "net = keras.layers.Activation('relu')(net)\n",
    "net = keras.layers.Dense(1)(net)                            # 출력을 하나로 모아줌\n",
    "outputs = keras.layers.Activation('sigmoid')(net)           # activation function으로 sigmoid를 사용해 0~1사이의 값으로 분류\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)  # 모델의 input layer과 ouput layer을 결정\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])    # 모델 학습 방식 설정 (optimizer, loss function, metric(평가지표)) (모델을 빌드하고 학습하기 전에 컴파일하는 것)\n",
    "\n",
    "model.summary()                                             # 모델의 정보 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5014a",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a79372a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.5057 - acc: 0.7208\n",
      "Epoch 00001: val_acc improved from -inf to 0.89153, saving model to ../models/2022_01_06_16_31_20.h5\n",
      "83/82 [==============================] - 4s 53ms/step - loss: 0.5046 - acc: 0.7219 - val_loss: 0.2830 - val_acc: 0.8915\n",
      "Epoch 2/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.9013\n",
      "Epoch 00002: val_acc improved from 0.89153 to 0.95254, saving model to ../models/2022_01_06_16_31_20.h5\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.2673 - acc: 0.9022 - val_loss: 0.1635 - val_acc: 0.9525\n",
      "Epoch 3/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9293\n",
      "Epoch 00003: val_acc improved from 0.95254 to 0.96610, saving model to ../models/2022_01_06_16_31_20.h5\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.1874 - acc: 0.9286 - val_loss: 0.1335 - val_acc: 0.9661\n",
      "Epoch 4/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9508\n",
      "Epoch 00004: val_acc improved from 0.96610 to 0.97966, saving model to ../models/2022_01_06_16_31_20.h5\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.1428 - acc: 0.9509 - val_loss: 0.0707 - val_acc: 0.9797\n",
      "Epoch 5/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9543\n",
      "Epoch 00005: val_acc did not improve from 0.97966\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.1421 - acc: 0.9528 - val_loss: 0.1601 - val_acc: 0.9492\n",
      "Epoch 6/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9524\n",
      "Epoch 00006: val_acc did not improve from 0.97966\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.1345 - acc: 0.9520 - val_loss: 0.1561 - val_acc: 0.9593\n",
      "Epoch 7/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9621\n",
      "Epoch 00007: val_acc improved from 0.97966 to 0.98644, saving model to ../models/2022_01_06_16_31_20.h5\n",
      "83/82 [==============================] - 3s 32ms/step - loss: 0.1093 - acc: 0.9618 - val_loss: 0.0694 - val_acc: 0.9864\n",
      "Epoch 8/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9686- ETA: 1s \n",
      "Epoch 00008: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 31ms/step - loss: 0.0860 - acc: 0.9690 - val_loss: 0.0626 - val_acc: 0.9797\n",
      "Epoch 9/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9717\n",
      "Epoch 00009: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.0935 - acc: 0.9720 - val_loss: 0.0652 - val_acc: 0.9864\n",
      "Epoch 10/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9783\n",
      "Epoch 00010: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 32ms/step - loss: 0.0757 - acc: 0.9788 - val_loss: 0.0625 - val_acc: 0.9864\n",
      "Epoch 11/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9752\n",
      "Epoch 00011: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.0719 - acc: 0.9754 - val_loss: 0.0819 - val_acc: 0.9797\n",
      "Epoch 12/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9816\n",
      "Epoch 00012: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0572 - acc: 0.9811 - val_loss: 0.0645 - val_acc: 0.9797\n",
      "Epoch 13/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9801- ETA: 0s - loss: 0.0545 - acc: 0.980\n",
      "Epoch 00013: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 32ms/step - loss: 0.0547 - acc: 0.9800 - val_loss: 0.0659 - val_acc: 0.9831\n",
      "Epoch 14/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9843\n",
      "Epoch 00014: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0537 - acc: 0.9841 - val_loss: 0.1087 - val_acc: 0.9763\n",
      "Epoch 15/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9826\n",
      "Epoch 00015: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0572 - acc: 0.9819 - val_loss: 0.1145 - val_acc: 0.9695\n",
      "Epoch 16/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9828\n",
      "Epoch 00016: val_acc did not improve from 0.98644\n",
      "83/82 [==============================] - 3s 30ms/step - loss: 0.0558 - acc: 0.9826 - val_loss: 0.0876 - val_acc: 0.9729\n",
      "Epoch 17/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9855\n",
      "Epoch 00017: val_acc did not improve from 0.98644\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.0502 - acc: 0.9856 - val_loss: 0.0658 - val_acc: 0.9763\n",
      "Epoch 18/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9895- ETA: 0s - loss: 0.0325 - acc: 0.\n",
      "Epoch 00018: val_acc improved from 0.98644 to 0.98983, saving model to ../models/2022_01_06_16_31_20.h5\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0346 - acc: 0.9898 - val_loss: 0.0403 - val_acc: 0.9898\n",
      "Epoch 19/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9919\n",
      "Epoch 00019: val_acc did not improve from 0.98983\n",
      "83/82 [==============================] - 3s 32ms/step - loss: 0.0308 - acc: 0.9921 - val_loss: 0.0482 - val_acc: 0.9831\n",
      "Epoch 20/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9916\n",
      "Epoch 00020: val_acc did not improve from 0.98983\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.0322 - acc: 0.9913 - val_loss: 0.0441 - val_acc: 0.9864\n",
      "Epoch 21/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9919- ETA: 0s - loss: 0.0319 - acc: 0.99\n",
      "Epoch 00021: val_acc did not improve from 0.98983\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0304 - acc: 0.9921 - val_loss: 0.0342 - val_acc: 0.9898\n",
      "Epoch 22/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9907\n",
      "Epoch 00022: val_acc improved from 0.98983 to 0.99322, saving model to ../models/2022_01_06_16_31_20.h5\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0303 - acc: 0.9906 - val_loss: 0.0324 - val_acc: 0.9932\n",
      "Epoch 23/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9924\n",
      "Epoch 00023: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.0432 - val_acc: 0.9898\n",
      "Epoch 24/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9924\n",
      "Epoch 00024: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.0246 - acc: 0.9924 - val_loss: 0.0345 - val_acc: 0.9864\n",
      "Epoch 25/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9903\n",
      "Epoch 00025: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 32ms/step - loss: 0.0267 - acc: 0.9902 - val_loss: 0.0377 - val_acc: 0.9898\n",
      "Epoch 26/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9938\n",
      "Epoch 00026: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 32ms/step - loss: 0.0212 - acc: 0.9940 - val_loss: 0.0377 - val_acc: 0.9898\n",
      "Epoch 27/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9923\n",
      "Epoch 00027: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 2s 28ms/step - loss: 0.0247 - acc: 0.9924 - val_loss: 0.0421 - val_acc: 0.9864\n",
      "Epoch 28/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9920\n",
      "Epoch 00028: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 2s 29ms/step - loss: 0.0244 - acc: 0.9921 - val_loss: 0.0385 - val_acc: 0.9898\n",
      "Epoch 29/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9919\n",
      "Epoch 00029: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0223 - acc: 0.9921 - val_loss: 0.0392 - val_acc: 0.9898\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/82 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9926\n",
      "Epoch 00030: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0257 - acc: 0.9921 - val_loss: 0.0396 - val_acc: 0.9864\n",
      "Epoch 31/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9930\n",
      "Epoch 00031: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0252 - acc: 0.9928 - val_loss: 0.0384 - val_acc: 0.9864\n",
      "Epoch 32/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9924\n",
      "Epoch 00032: val_acc did not improve from 0.99322\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "83/82 [==============================] - 3s 37ms/step - loss: 0.0206 - acc: 0.9924 - val_loss: 0.0403 - val_acc: 0.9864\n",
      "Epoch 33/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9954- ETA:\n",
      "Epoch 00033: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0138 - acc: 0.9955 - val_loss: 0.0387 - val_acc: 0.9864\n",
      "Epoch 34/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9946\n",
      "Epoch 00034: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0187 - acc: 0.9947 - val_loss: 0.0365 - val_acc: 0.9864\n",
      "Epoch 35/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9962\n",
      "Epoch 00035: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0150 - acc: 0.9962 - val_loss: 0.0371 - val_acc: 0.9864\n",
      "Epoch 36/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 00036: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 2s 26ms/step - loss: 0.0119 - acc: 0.9966 - val_loss: 0.0396 - val_acc: 0.9864\n",
      "Epoch 37/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9961\n",
      "Epoch 00037: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 32ms/step - loss: 0.0146 - acc: 0.9962 - val_loss: 0.0396 - val_acc: 0.9864\n",
      "Epoch 38/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9966\n",
      "Epoch 00038: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0127 - acc: 0.9966 - val_loss: 0.0334 - val_acc: 0.9898\n",
      "Epoch 39/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9939\n",
      "Epoch 00039: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0175 - acc: 0.9940 - val_loss: 0.0401 - val_acc: 0.9864\n",
      "Epoch 40/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9954\n",
      "Epoch 00040: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0172 - acc: 0.9955 - val_loss: 0.0370 - val_acc: 0.9864\n",
      "Epoch 41/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9950\n",
      "Epoch 00041: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 35ms/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.0398 - val_acc: 0.9831\n",
      "Epoch 42/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9950\n",
      "Epoch 00042: val_acc did not improve from 0.99322\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0183 - acc: 0.9947 - val_loss: 0.0362 - val_acc: 0.9864\n",
      "Epoch 43/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9938\n",
      "Epoch 00043: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0361 - val_acc: 0.9864\n",
      "Epoch 44/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9973\n",
      "Epoch 00044: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0369 - val_acc: 0.9864\n",
      "Epoch 45/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9954\n",
      "Epoch 00045: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0359 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 00046: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0167 - acc: 0.9947 - val_loss: 0.0355 - val_acc: 0.9898\n",
      "Epoch 47/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9965\n",
      "Epoch 00047: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0135 - acc: 0.9966 - val_loss: 0.0364 - val_acc: 0.9898\n",
      "Epoch 48/50\n",
      "82/82 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9939\n",
      "Epoch 00048: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 33ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0364 - val_acc: 0.9864\n",
      "Epoch 49/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 00049: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 3s 34ms/step - loss: 0.0164 - acc: 0.9951 - val_loss: 0.0352 - val_acc: 0.9898\n",
      "Epoch 50/50\n",
      "81/82 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9961\n",
      "Epoch 00050: val_acc did not improve from 0.99322\n",
      "83/82 [==============================] - 2s 26ms/step - loss: 0.0148 - acc: 0.9962 - val_loss: 0.0352 - val_acc: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ac6e77ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')     # 모델을 학습한 시간\n",
    "\n",
    "model.fit_generator(\n",
    "    # 주어진 epoch=50 만큼 모델 학습\n",
    "    train_generator, epochs=50, steps_per_epoch=2649/32, validation_steps=295/32, validation_data=val_generator,\n",
    "    # stpes_per_epoch : 한 번 epoch 돌 때 데이터를 몇 번 볼 것인가\n",
    "    # validation_steps : 한 번 epoch 돌고 난 후 validation accuracy를 측정할 때 validation data를 몇번 볼 것인가\n",
    "    callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint('../models/%s.h5' % (start_time), monitor='val_acc', save_best_only=True, mode='max', verbose=1),  # 파일명을 모델을 학습하는 시간으로 하고 가장 accuracy가 좋은 모델만 저장\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=10, verbose=1, mode='auto', min_lr=1e-05)             # 모델의 개선이 없을 경우 learning rate를 조절해 모델의 개선을 유도\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ccd75",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19f0300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9932203389830508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "model = keras.models.load_model('../models/%s.h5' % (start_time))\n",
    "\n",
    "y_pred = model.predict(x_val/255.)\n",
    "y_pred_logical = (y_pred > 0.5).astype(np.int)\n",
    "\n",
    "print ('test acc: %s' % accuracy_score(y_val, y_pred_logical))\n",
    "cm = confusion_matrix(y_val, y_pred_logical)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34995af2",
   "metadata": {},
   "source": [
    "# Distribution of Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cf2b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.distplot(y_pred, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddffac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
